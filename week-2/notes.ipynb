{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a49a61",
   "metadata": {},
   "source": [
    "# Using LLMs and prompting-based approaches\n",
    "\n",
    "LLMs have been trained with massive amounts of data scraped from the internet and they usually come pre-trained. During this pre-training they learn, not only to predict the next word, but various association such as Style, tone and domain. GPT3 was one of the first to approach prompting in a few-shot way, claiming that prompting is a way to extract or retrieve form the model the capabilities. In the pre-training the model is not told that, for example, some language is not adequate, to be positive, polite and all that stuff. They have the ability to learn new tasks form some examples, few-shots. Prompting is providing instrunctions or inputs to a PTM (pretrained model) to guide its output. Promts can take many forms (Instructions, questions), so do outputs. Promting guides the model to a desired output:\n",
    "\n",
    "* Specificity: Leverage to a new emergent capabilities, such as writing poems. Previously you had to train a new model for this.\n",
    "\n",
    "* Control\n",
    "\n",
    "* Efficiency\n",
    "\n",
    "* Creativity\n",
    "\n",
    "PROMOTING IS NOT A SCIENCE, IT'S AN ART. (Lol NO, WTF?!)\n",
    "\n",
    "## Prompting techniques\n",
    "\n",
    "### Zero-shot prompting\n",
    "\n",
    "Provide simple instructions or a question for the specific task but no example\n",
    "\n",
    "### Few-Shot prompting\n",
    "\n",
    "Provide instructions or questions but also one or more examples of the desired output.\n",
    "\n",
    "### Chain of thought prompting\n",
    "\n",
    "Enables complex reasoning capabilities through an immediate reasoning steps. Inject the reasoning logic to complete the task as part of the task. This way the provide intermediate steps or tokens, which usually result in a better output.\n",
    "\n",
    "### Prompt chaining\n",
    "\n",
    "Combine multiple prompts together, breaking down a task into smaller subtasks.\n",
    "\n",
    "### Other\n",
    "\n",
    "**Tree of thought** can be used to encourage the LLM to break the problem down into smaller steps and explore multiple reasoning paths.\n",
    "\n",
    "## In context learning\n",
    "\n",
    "It's a generalization of few-shot where the LLM is provided a context as a part of the prompt and ask the model tu use it. Retrieval Augmented Generation (RAG) is a form of in-context learning. You give the information that you want the model to understand and use in the prompt. RAG adds on top of the search engine a LLM that looks into the relevant information retrieved by the search engines.\n",
    "\n",
    "## Prompt templates\n",
    "\n",
    "A convenient way to create reusable templates that contain certain elements that can be modified while keeping the prompt fixed. Such as \"Give a summary of {topic}\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
